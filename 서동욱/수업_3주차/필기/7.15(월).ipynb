{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 돔트리\n",
    "# CSS selector 한줄이라도 짧음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawling\n",
    "- 텍스트 마이닝, 데이터 마이닝\n",
    "- NLP 포커스 말뭉치 : 언어습관\n",
    "- 실 데이터를 누적함.\n",
    "- 세종21기반으로 형태소 분석기 만든게 카카오의 카이\n",
    "- Systematically browses\n",
    "- 구글 검색엔진의 시발점\n",
    "- Focused Crawling을 할것 (원하는 범위까지만 정해진 방식으로 가져오기)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 링크를 가져와서 재귀적으로 돌릴것임.\n",
    "- URL List를 어떻게 관리 할것인지\n",
    "- MultiThread, 분산처리가 필요함.\n",
    "- 이미 Scrapy라는 패키지로 만들어져있기는 함. (이미 봇임).\n",
    "- BeautifulSoup을 통해서 Dom객체 만들어서 parsing할 것임.\n",
    "- 같은 내용인데 다른 url인지, 들어갔던건지, 걸러내기.\n",
    "- 내부 저장부분은 html.text 저장하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시드 주소 : http://example.webscraping.com/places/default/index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a tag에서 href가 항상 하이퍼링크 predefined 형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "def download(method, url, \n",
    "             param = None, data = None, \n",
    "            timeout = 1,maxretries = 3):\n",
    "    \n",
    "    headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36'}\n",
    "    #headers = None\n",
    "    \n",
    "    try:\n",
    "        resp = requests.request(method, url,\n",
    "                                params= param,\n",
    "                                data=data, headers=headers)\n",
    "        resp.raise_for_status()\n",
    "        \n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if 500 <= e.response.status_code < 600 and maxretries > 0: \n",
    "            time.sleep(timeout) # param에따라 몇초 기다릴지 결정 할 수가 있다.\n",
    "            print(maxretries) # 재귀적으로 자기 자신을 부르게 코드를 짜면 된다.\n",
    "            resp = download(method,\n",
    "                            url, param = param, data=data,\n",
    "                            timeout=timeout,\n",
    "                            maxretries = maxretries - 1)\n",
    "        else:\n",
    "            print(e.response.status_code)\n",
    "            print(e.response.reason)\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from requests import compat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://example.webscraping.com/places/default/index'\n",
    "html = download(\"get\",url)\n",
    "dom = BeautifulSoup(html.text,\"lxml\")\n",
    "dom.select(\"#mainFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseURL(seed):\n",
    "    html = download(\"get\",seed)\n",
    "    dom = BeautifulSoup(html.text,\"lxml\")\n",
    "    \n",
    "    if len(dom.select(\"#mainFrame\")) < 1:\n",
    "        return []\n",
    "    \n",
    "    seed = compat.urljoin(seed,dom.select('#mainFrame')[0]['src'])\n",
    "    html = download(\"get\",seed)\n",
    "    dom = BeautifulSoup(html.text,\"lxml\")\n",
    "    \n",
    "    return [compat.urljoin(html.url,_[\"href\"])\n",
    "                 for _ in dom.find_all(\"a\") \n",
    "            if _.has_attr(\"href\") and len(_[\"href\"]) > 3\n",
    "           and checkBlog(compat.urljoin(seed,_[\"href\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queue: 0, Seen: 1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "pop from empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-2aa0e882c081>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mbaseURL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# FIFO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mseen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbaseURL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from empty list"
     ]
    }
   ],
   "source": [
    "queue = list()\n",
    "queue.append('http://example.webscraping.com/places/default/index')\n",
    "\n",
    "seen = list()\n",
    "\n",
    "while True:\n",
    "    baseURL = queue.pop(0) # FIFO\n",
    "    seen.append(baseURL)\n",
    "    \n",
    "    time.sleep(0.2) # 너무 빠르면 안된다.\n",
    "    \n",
    "    linkList = parseURL(baseURL)\n",
    "    for link in linkList:  # 중복되는 url은 빼주어야 한다. (Home 같은 것)\n",
    "        if link not in queue and link not in seen:\n",
    "            queue.append(link)\n",
    "    print(\"Queue: {0}, Seen: {1}\".format(len(queue),len(seen)))\n",
    "    # URL Seen : BaseURL에 쓰인 것을 다른 table에서 관리하다가 있으면 피한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseURL(seed):\n",
    "    html = download(\"get\",geturl(seed),getparams(seed))\n",
    "    dom = BeautifulSoup(html.text,\"lxml\")\n",
    "\n",
    "    if len(dom.select(\"#mainFrame\")) < 1:\n",
    "        return []\n",
    "    \n",
    "    seed = compat.urljoin(seed,dom.select('#mainFrame')[0]['src'])\n",
    "\n",
    "    html = download(\"get\",geturl(seed),getparams(seed))\n",
    "    dom = BeautifulSoup(html.text,\"lxml\")\n",
    "\n",
    "    return [compat.urljoin(html.url,_[\"href\"])\n",
    "                 for _ in dom.find_all(\"a\") \n",
    "            if _.has_attr(\"href\") and len(_[\"href\"]) > 3\n",
    "           and checkBlog(compat.urljoin(seed,_[\"href\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geturl(urlsrc):\n",
    "    if '?' in urlsrc:\n",
    "        return urlsrc.split('?')[0]+'?'\n",
    "    else:\n",
    "        return urlsrc\n",
    "\n",
    "def getparams(urlsrc):\n",
    "    if '?' in  urlsrc:\n",
    "        try:\n",
    "            paramList = urlsrc.split('?')[1].split('&')\n",
    "            params = {_.split('=')[0]:compat.unquote(_.split('=')[1]) for _ in paramList}\n",
    "            return params\n",
    "        except:\n",
    "            print(_)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "pop from empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-d251e94a352e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# BFS Search (너비 우선 탐색)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mbaseURL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# FIFO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m#baseURL = queue.pop(-1) # Stack으로 해서 깊이우선 탐색\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mseen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbaseURL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from empty list"
     ]
    }
   ],
   "source": [
    "queue = list()\n",
    "queue.extend([_[\"href\"] \n",
    "  for _ in dom2.select(\"a.sh_blog_title._sp_each_url._sp_each_title\")\n",
    " if checkBlog(_[\"href\"])])\n",
    "\n",
    "seen = list()\n",
    "\n",
    "# BFS Search (너비 우선 탐색)\n",
    "while True:\n",
    "    baseURL = queue.pop(0) # FIFO\n",
    "    #baseURL = queue.pop(-1) # Stack으로 해서 깊이우선 탐색\n",
    "    seen.append(baseURL)\n",
    "    # URL Seen : BaseURL에 쓰인 것을 다른 table에서 관리하다가 있으면 피한다.\n",
    "    \n",
    "    time.sleep(0.5) # 너무 빠르면 안된다.\n",
    "    \n",
    "    linkList = parseURL(baseURL)\n",
    "    for link in linkList:  # 중복되는 url은 빼주어야 한다. (Home 같은 것)\n",
    "        if link not in queue and link not in seen:\n",
    "            queue.append(link)\n",
    "    print(\"Queue: {0}, Seen: {1}\".format(len(queue),len(seen)))\n",
    "\n",
    "# Back of Add Model을 만들 수 있다.\n",
    "# Or not vector(?) \n",
    "# 저차원으로 가면 Word Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://blog.naver.com/cheawhi?Redirect=Log&logNo=221588720464',\n",
       " 'https://blog.naver.com/imagetech1?Redirect=Log&logNo=221530358950']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NAVER\n",
    "url = \"https://search.naver.com/search.naver?sm=top_hty&fbm=0&ie=utf8&query=%EB%B0%95%EB%B3%B4%EC%98%81\"\n",
    "param = getparams(url)\n",
    "urlsrc = geturl(url)\n",
    "\n",
    "html = download('get',urlsrc,param)\n",
    "dom2 = BeautifulSoup(html.text,\"lxml\")\n",
    "\n",
    "([_[\"href\"] \n",
    "  for _ in dom2.select(\"a.sh_blog_title._sp_each_url._sp_each_title\")\n",
    " if checkBlog(_[\"href\"])]) # 네이버 블로그만 가져오기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://adam24eve.tistory.com/858',\n",
       " 'http://bfh188.tistory.com/5',\n",
       " 'http://clickplease.tistory.com/18',\n",
       " 'http://listup.tistory.com/248']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DAUM\n",
    "url = \"https://search.daum.net/search?w=tot&DA=YZR&t__nil_searchbox=btn&sug=&sugo=&q=%EB%B0%95%EB%B3%B4%EC%98%81\"\n",
    "param = getparams(url)\n",
    "urlsrc = geturl(url)\n",
    "\n",
    "html = download('get',urlsrc,param)\n",
    "dom2 = BeautifulSoup(html.text,\"lxml\")\n",
    "\n",
    "([_[\"href\"] \n",
    "  for _ in dom2.select(\"#blogColl a.f_link_b\")\n",
    " if checktistory(_[\"href\"])]) # 다음 블로그만 가져오기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseURL(seed):\n",
    "    html = download(\"get\",seed[0])\n",
    "    dom = BeautifulSoup(html.text,\"lxml\")\n",
    "    \n",
    "    return [(compat.urljoin(seed[0],_[\"href\"]),seed[1]+1) # 특정 depth까지만\n",
    "                 for _ in dom.find_all(\"a\") \n",
    "            if seed[1] < 2 and _.has_attr(\"href\") and len(_[\"href\"]) > 3\n",
    "           and checktistory(compat.urljoin(seed[0],_[\"href\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queue: 45, Seen: 1\n",
      "Queue: 68, Seen: 2\n",
      "Queue: 81, Seen: 3\n",
      "Queue: 105, Seen: 4\n",
      "Queue: 104, Seen: 5\n",
      "Queue: 103, Seen: 6\n",
      "Queue: 102, Seen: 7\n",
      "Queue: 101, Seen: 8\n",
      "Queue: 100, Seen: 9\n",
      "Queue: 99, Seen: 10\n",
      "Queue: 98, Seen: 11\n",
      "Queue: 97, Seen: 12\n",
      "Queue: 96, Seen: 13\n",
      "Queue: 95, Seen: 14\n",
      "Queue: 94, Seen: 15\n",
      "Queue: 93, Seen: 16\n",
      "Queue: 92, Seen: 17\n",
      "Queue: 91, Seen: 18\n",
      "Queue: 90, Seen: 19\n",
      "Queue: 89, Seen: 20\n",
      "Queue: 88, Seen: 21\n",
      "Queue: 87, Seen: 22\n",
      "Queue: 86, Seen: 23\n",
      "Queue: 85, Seen: 24\n",
      "Queue: 84, Seen: 25\n",
      "Queue: 83, Seen: 26\n",
      "Queue: 82, Seen: 27\n",
      "Queue: 81, Seen: 28\n",
      "Queue: 80, Seen: 29\n",
      "Queue: 79, Seen: 30\n",
      "Queue: 78, Seen: 31\n",
      "Queue: 77, Seen: 32\n",
      "Queue: 76, Seen: 33\n",
      "Queue: 75, Seen: 34\n",
      "Queue: 74, Seen: 35\n",
      "Queue: 73, Seen: 36\n",
      "Queue: 72, Seen: 37\n",
      "Queue: 71, Seen: 38\n",
      "Queue: 70, Seen: 39\n",
      "Queue: 69, Seen: 40\n",
      "Queue: 68, Seen: 41\n",
      "Queue: 67, Seen: 42\n",
      "Queue: 66, Seen: 43\n",
      "Queue: 65, Seen: 44\n",
      "Queue: 64, Seen: 45\n",
      "Queue: 63, Seen: 46\n",
      "Queue: 62, Seen: 47\n",
      "Queue: 61, Seen: 48\n",
      "Queue: 60, Seen: 49\n",
      "Queue: 59, Seen: 50\n",
      "Queue: 58, Seen: 51\n",
      "Queue: 57, Seen: 52\n",
      "Queue: 56, Seen: 53\n",
      "Queue: 55, Seen: 54\n",
      "Queue: 54, Seen: 55\n",
      "Queue: 53, Seen: 56\n",
      "Queue: 52, Seen: 57\n",
      "Queue: 51, Seen: 58\n",
      "Queue: 50, Seen: 59\n",
      "Queue: 49, Seen: 60\n",
      "Queue: 48, Seen: 61\n",
      "Queue: 47, Seen: 62\n",
      "Queue: 46, Seen: 63\n",
      "Queue: 45, Seen: 64\n",
      "Queue: 44, Seen: 65\n",
      "Queue: 43, Seen: 66\n",
      "Queue: 42, Seen: 67\n",
      "Queue: 41, Seen: 68\n",
      "Queue: 40, Seen: 69\n",
      "Queue: 39, Seen: 70\n",
      "Queue: 38, Seen: 71\n",
      "Queue: 37, Seen: 72\n",
      "Queue: 36, Seen: 73\n",
      "Queue: 35, Seen: 74\n",
      "Queue: 34, Seen: 75\n",
      "Queue: 33, Seen: 76\n",
      "Queue: 32, Seen: 77\n",
      "Queue: 31, Seen: 78\n",
      "Queue: 30, Seen: 79\n",
      "Queue: 29, Seen: 80\n",
      "Queue: 28, Seen: 81\n",
      "Queue: 27, Seen: 82\n",
      "Queue: 26, Seen: 83\n",
      "Queue: 25, Seen: 84\n",
      "Queue: 24, Seen: 85\n",
      "Queue: 23, Seen: 86\n",
      "Queue: 22, Seen: 87\n",
      "Queue: 21, Seen: 88\n",
      "Queue: 20, Seen: 89\n",
      "Queue: 19, Seen: 90\n",
      "Queue: 18, Seen: 91\n",
      "Queue: 17, Seen: 92\n",
      "Queue: 16, Seen: 93\n",
      "Queue: 15, Seen: 94\n",
      "Queue: 14, Seen: 95\n",
      "Queue: 13, Seen: 96\n",
      "Queue: 12, Seen: 97\n",
      "Queue: 11, Seen: 98\n",
      "Queue: 10, Seen: 99\n",
      "Queue: 9, Seen: 100\n",
      "Queue: 8, Seen: 101\n",
      "Queue: 7, Seen: 102\n",
      "Queue: 6, Seen: 103\n",
      "Queue: 5, Seen: 104\n",
      "Queue: 4, Seen: 105\n",
      "Queue: 3, Seen: 106\n",
      "Queue: 2, Seen: 107\n",
      "Queue: 1, Seen: 108\n",
      "Queue: 0, Seen: 109\n"
     ]
    }
   ],
   "source": [
    "queue = list()\n",
    "queue.extend([(_[\"href\"] ,1) # url and depth\n",
    "  for _ in dom2.select(\"#blogColl a.f_link_b\")\n",
    " if checktistory(_[\"href\"])])\n",
    "\n",
    "seen = list()\n",
    "\n",
    "while queue:\n",
    "    \n",
    "    baseURL = queue.pop(0) \n",
    "    seen.append(baseURL)\n",
    "    \n",
    "    time.sleep(0.1) # 너무 빠르면 안된다.\n",
    "    \n",
    "    linkList = parseURL(baseURL)\n",
    "    for link in linkList:  # 중복되는 url은 빼주어야 한다. (Home 같은 것)\n",
    "        if link not in queue and link not in seen:\n",
    "            queue.append(link)\n",
    "    print(\"Queue: {0}, Seen: {1}\".format(len(queue),len(seen)))\n",
    "\n",
    "    \n",
    "# Focused crawling은 얼마나 레퍼런스됬는지 볼때사용됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checktistory(url):\n",
    "    return compat.urlparse(url)[1].find('tistory.com') != -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('http://adam24eve.tistory.com/858', 1)\n",
      "('http://bfh188.tistory.com/5', 1)\n",
      "('http://clickplease.tistory.com/18', 1)\n",
      "('http://listup.tistory.com/248', 1)\n",
      "('http://adam24eve.tistory.com/category', 2)\n",
      "('http://adam24eve.tistory.com/category/Cosmos', 2)\n",
      "('http://adam24eve.tistory.com/category/Mystery%20world', 2)\n",
      "('http://adam24eve.tistory.com/category/Star', 2)\n",
      "('http://adam24eve.tistory.com/category/Political%20', 2)\n",
      "('http://adam24eve.tistory.com/category/It-game', 2)\n",
      "('http://adam24eve.tistory.com/guestbook', 2)\n",
      "('https://adam24eve.tistory.com/rss', 2)\n",
      "('http://adam24eve.tistory.com/858', 2)\n",
      "('http://adam24eve.tistory.com/tag/%EA%B9%80%EC%98%81%EA%B4%91', 2)\n",
      "('http://adam24eve.tistory.com/tag/%EA%B9%80%EC%98%81%EA%B4%91%20%EB%82%98%EC%9D%B4', 2)\n",
      "('http://adam24eve.tistory.com/tag/%EA%B9%80%EC%98%81%EA%B4%91%20%EB%B0%95%EB%B3%B4%EC%98%81%20%EC%97%B4%EC%95%A0', 2)\n",
      "('http://adam24eve.tistory.com/tag/%EA%B9%80%EC%98%81%EA%B4%91%20%ED%82%A4', 2)\n",
      "('http://adam24eve.tistory.com/tag/%EB%AF%B8%EC%9A%B0%EC%83%88', 2)\n",
      "('http://adam24eve.tistory.com/tag/%EB%AF%B8%EC%9A%B4%EC%9A%B0%EB%A6%AC%EC%83%88%EB%81%BC', 2)\n",
      "('http://adam24eve.tistory.com/tag/%EB%B0%95%EB%B3%B4%EC%98%81', 2)\n",
      "('http://adam24eve.tistory.com/tag/%EB%B0%95%EB%B3%B4%EC%98%81%20%ED%82%A4', 2)\n",
      "('http://adam24eve.tistory.com/860?category=820301', 2)\n",
      "('http://adam24eve.tistory.com/859?category=820301', 2)\n",
      "('http://adam24eve.tistory.com/857?category=820301', 2)\n",
      "('http://adam24eve.tistory.com/855?category=820301', 2)\n",
      "('http://adam24eve.tistory.com/859', 2)\n",
      "('http://adam24eve.tistory.com/994', 2)\n",
      "('http://adam24eve.tistory.com/862', 2)\n",
      "('http://adam24eve.tistory.com/861', 2)\n",
      "('http://adam24eve.tistory.com/860', 2)\n",
      "('http://adam24eve.tistory.com/857', 2)\n",
      "('http://adam24eve.tistory.com/856', 2)\n",
      "('http://adam24eve.tistory.com/855', 2)\n",
      "('http://adam24eve.tistory.com/854', 2)\n",
      "('http://adam24eve.tistory.com/notice/406', 2)\n",
      "('http://adam24eve.tistory.com/993', 2)\n",
      "('http://adam24eve.tistory.com/992', 2)\n",
      "('http://adam24eve.tistory.com/991', 2)\n",
      "('http://adam24eve.tistory.com/990', 2)\n",
      "('http://adam24eve.tistory.com/988#comment15507887', 2)\n",
      "('http://adam24eve.tistory.com/957#comment15494479', 2)\n",
      "('http://adam24eve.tistory.com/810#comment15492825', 2)\n",
      "('http://adam24eve.tistory.com/934#comment15492756', 2)\n",
      "('http://adam24eve.tistory.com/114#comment15492408', 2)\n",
      "('https://adam24eve.tistory.com/manage', 2)\n",
      "('https://adam24eve.tistory.com/manage/entry/post', 2)\n",
      "('http://bfh188.tistory.com/5#dkBody', 2)\n",
      "('http://bfh188.tistory.com/category', 2)\n",
      "('http://bfh188.tistory.com/category/star%20profile', 2)\n",
      "('http://bfh188.tistory.com/category/star%20issue', 2)\n",
      "('http://bfh188.tistory.com/category/media', 2)\n",
      "('http://bfh188.tistory.com/category/music%20life', 2)\n",
      "('http://bfh188.tistory.com/category/daily%20life', 2)\n",
      "('http://bfh188.tistory.com/guestbook', 2)\n",
      "('http://bfh188.tistory.com/archive/201906', 2)\n",
      "('http://bfh188.tistory.com/archive/201907', 2)\n",
      "('http://bfh188.tistory.com/archive/201908', 2)\n",
      "('http://bfh188.tistory.com/archive/20190716', 2)\n",
      "('http://bfh188.tistory.com/archive/20190717', 2)\n",
      "('http://bfh188.tistory.com/archive/20190718', 2)\n",
      "('http://bfh188.tistory.com/archive/20190719', 2)\n",
      "('http://bfh188.tistory.com/tag', 2)\n",
      "('https://bfh188.tistory.com/manage/entry/post', 2)\n",
      "('https://bfh188.tistory.com/rss', 2)\n",
      "('https://bfh188.tistory.com/manage', 2)\n",
      "('http://bfh188.tistory.com/5?category=718946', 2)\n",
      "('http://bfh188.tistory.com/4?category=718946', 2)\n",
      "('http://bfh188.tistory.com/3?category=718946', 2)\n",
      "('http://bfh188.tistory.com/2?category=718946', 2)\n",
      "('http://www.tistory.com', 2)\n",
      "('http://clickplease.tistory.com/18#dkBody', 2)\n",
      "('http://clickplease.tistory.com/18#dkGnb', 2)\n",
      "('https://clickplease.tistory.com/manage/entry/post', 2)\n",
      "('https://clickplease.tistory.com/manage', 2)\n",
      "('http://clickplease.tistory.com/tag', 2)\n",
      "('http://clickplease.tistory.com/guestbook', 2)\n",
      "('https://clickplease.tistory.com/rss', 2)\n",
      "('http://clickplease.tistory.com/category', 2)\n",
      "('http://clickplease.tistory.com/category/%EA%B1%B4%EA%B0%95', 2)\n",
      "('http://clickplease.tistory.com/category/%EC%9E%90%EA%B8%B0%EA%B3%84%EB%B0%9C', 2)\n",
      "('http://clickplease.tistory.com/category/%EC%BB%B4%ED%93%A8%ED%84%B0', 2)\n",
      "('http://clickplease.tistory.com/category/%EA%B7%B8%EB%83%A5', 2)\n",
      "('http://clickplease.tistory.com/category/그냥', 2)\n",
      "('http://clickplease.tistory.com/18?category=798294', 2)\n",
      "('http://listup.tistory.com/248#dkBody', 2)\n",
      "('http://listup.tistory.com/248#dkGnb', 2)\n",
      "('https://listup.tistory.com/manage/entry/post', 2)\n",
      "('https://listup.tistory.com/manage', 2)\n",
      "('http://listup.tistory.com/tag', 2)\n",
      "('http://listup.tistory.com/guestbook', 2)\n",
      "('https://listup.tistory.com/rss', 2)\n",
      "('http://listup.tistory.com/category', 2)\n",
      "('http://listup.tistory.com/248', 2)\n",
      "('http://listup.tistory.com/248#none', 2)\n",
      "('http://listup.tistory.com/tag/%EB%B0%95%EB%B3%B4%EC%98%81', 2)\n",
      "('http://listup.tistory.com/tag/%EB%B0%95%EB%B3%B4%EC%98%81%20%EB%82%98%EC%9D%B4', 2)\n",
      "('http://listup.tistory.com/tag/%EB%B0%95%EB%B3%B4%EC%98%81%20%EB%93%9C%EB%9D%BC%EB%A7%88', 2)\n",
      "('http://listup.tistory.com/tag/%EB%B0%95%EB%B3%B4%EC%98%81%20%EC%96%B4%EB%B9%84%EC%8A%A4', 2)\n",
      "('http://listup.tistory.com/tag/%EB%B0%95%EB%B3%B4%EC%98%81%20%EC%9D%B8%EC%8A%A4%ED%83%80%EA%B7%B8%EB%9E%A8', 2)\n",
      "('http://listup.tistory.com/tag/%EB%B0%95%EB%B3%B4%EC%98%81%20%ED%82%A4', 2)\n",
      "('http://listup.tistory.com/249', 2)\n",
      "('http://listup.tistory.com/329', 2)\n",
      "('http://listup.tistory.com/253', 2)\n",
      "('http://listup.tistory.com/251', 2)\n",
      "('http://listup.tistory.com/250', 2)\n",
      "('http://listup.tistory.com/247', 2)\n",
      "('http://listup.tistory.com/246', 2)\n",
      "('http://listup.tistory.com/245', 2)\n",
      "('http://listup.tistory.com/244', 2)\n"
     ]
    }
   ],
   "source": [
    "for i in seen:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = dom2.select(\"#blogColl a.f_link_b\")[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compat.urlparse(url)[1].find('tistory.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkBlog2(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규식으로 할거면 (.+?)[.]tistory.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-cb1e7ef8e165>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m seed = ([_[\"href\"] \n\u001b[0;32m      2\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdom2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"a.sh_blog_title._sp_each_url._sp_each_title\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m  if checkBlog(_[\"href\"])])[0]\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"get\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgeturl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetparams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"lxml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "seed = ([_[\"href\"] \n",
    "  for _ in dom2.select(\"a.sh_blog_title._sp_each_url._sp_each_title\")\n",
    " if checkBlog(_[\"href\"])])[0]\n",
    "html = download(\"get\",geturl(seed),param=getparams(seed))\n",
    "dom = BeautifulSoup(html.text,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/PostView.nhn?blogId=imagetech1&logNo=221530358950&from=search&redirect=Log&widgetTypeCall=true&directAccess=false'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dom.select('#mainFrame')[0]['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-cf2d1042628b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murljoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeturl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'#mainFrame'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'src'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'seed' is not defined"
     ]
    }
   ],
   "source": [
    "seed = compat.urljoin(geturl(seed),dom.select('#mainFrame')[0]['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-720ad58653ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdom2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'#mainFrame'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'src'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "dom2.select('#mainFrame')[0]['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParseResult(scheme='https', netloc='blog.naver.com', path='/dlqlwm14', params='', query='Redirect=Log&logNo=221529807195', fragment='')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compat.urlparse('https://blog.naver.com/dlqlwm14?Redirect=Log&logNo=221529807195')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkBlog(url):\n",
    "    return compat.urlparse(url)[1] == 'blog.naver.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkBlog('https://blog.naver.com/dlqlwm14?Redirect=Log&logNo=221529807195')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-e8c7780b5a60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_parent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"href\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdom2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".LC20lb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "[_.find_parent()[\"href\"] for _ in dom2.select(\".LC20lb\")][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseURL(seed):\n",
    "    html = download(\"get\",geturl(seed),param=getparams(seed))\n",
    "    dom = BeautifulSoup(html.text,\"lxml\")\n",
    "    \n",
    "    return [compat.urljoin(html.url,_[\"href\"])\n",
    "                 for _ in dom.find_all(\"a\") \n",
    "            if _.has_attr(\"href\") and not _[\"href\"].startswith('#')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geturl(urlsrc):\n",
    "    if '?' in urlsrc:\n",
    "        return urlsrc.split('?')[0]+'?'\n",
    "    else:\n",
    "        return urlsrc\n",
    "\n",
    "def getparams(urlsrc):\n",
    "    if '?' in  urlsrc:\n",
    "        paramList = urlsrc.split('?')[1].split('&')\n",
    "        params = {_.split('=')[0]:compat.unquote(_.split('=')[1]) for _ in paramList}\n",
    "        return params\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "pop from empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-bf83dd1af300>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# BFS Search (너비 우선 탐색)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mbaseURL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# FIFO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;31m#baseURL = queue.pop(-1) # Stack으로 해서 깊이우선 탐색\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mseen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbaseURL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from empty list"
     ]
    }
   ],
   "source": [
    "queue = list()\n",
    "#queue.append('https://www.google.com/search?newwindow=1&hl=en&source=hp&ei=wN8rXZW8NMn_8QWErqDgDg&q=박보영&oq=박보영&gs_l=psy-ab.3..0l10.2667.3629..3735...2.0..1.126.877.1j8......0....1..gws-wiz.....0..0i131.xCFY8trEo3I')\n",
    "#for _ in ParkList:\n",
    "#    queue.append(_[0])\n",
    "\n",
    "queue.extend([_.find_parent()[\"href\"] for _ in dom2.select(\".LC20lb\")])\n",
    "seen = list()\n",
    "\n",
    "# BFS Search (너비 우선 탐색)\n",
    "while True:\n",
    "    baseURL = queue.pop(0) # FIFO\n",
    "    #baseURL = queue.pop(-1) # Stack으로 해서 깊이우선 탐색\n",
    "    seen.append(baseURL)\n",
    "    # URL Seen : BaseURL에 쓰인 것을 다른 table에서 관리하다가 있으면 피한다.\n",
    "    \n",
    "    time.sleep(1) # 너무 빠르면 안된다.\n",
    "    \n",
    "    linkList = parseURL(baseURL)\n",
    "    for link in linkList:  # 중복되는 url은 빼주어야 한다. (Home 같은 것)\n",
    "        if link not in queue and link not in seen:\n",
    "            queue.append(link)\n",
    "    print(\"Queue: {0}, Seen: {1}\".format(len(queue),len(seen)))\n",
    "\n",
    "# Back of Add Model을 만들 수 있다.\n",
    "# Or not vector(?) \n",
    "# 저차원으로 가면 Word Embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터베이스를 만드려면 테이블관의 관계를 어떻게 할건지 스키마 구성해야함\n",
    "- 이미지만, 텍스트만 처리 혹은 구성할건지\n",
    "- 데이터베이스는 PK가 제일 중요하다(Unique). 절대로 문자열 쓰지마라.  \n",
    "DB는 빠르게 해쉬해야하는데 문자열이면 해쉬값을 못만든다.  \n",
    "- ID , url, 언제 Access했는지(date값), seen인지 체크\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 테이블 1개에 id, url, seen, date가 필요\n",
    "- url도 중복이 많이 생기기 때문에 참조하는 형태로 하면 속도가 빨라질 것이다.\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "table1 = id, path, param seen, date  \n",
    "table2 = id, netloc, date(timestamp 방식)  \n",
    "url = netloc + path + param  \n",
    "\n",
    "table1과 table2를 join시켜서 table2에 focused 크롤링 하면 된다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sql3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sql3.connect('myB.db',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x186c6f60b20>"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.executescript(\"\"\"\n",
    "    DROP TABLE IF EXISTS table1;\n",
    "    CREATE TABLE table1(\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
    "    table2_id INTEGER NOT NULL,\n",
    "    path TEXT NOT NULL,\n",
    "    param TEXT,\n",
    "    depth INTEGER NOT NULL,\n",
    "    inbound INTEGER NOT NULL,\n",
    "    seen BOOLEAN DEFAULT FALSE,\n",
    "    date TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL\n",
    "    );\n",
    "    \n",
    "    DROP TABLE IF EXISTS table2;\n",
    "    CREATE TABLE table2(\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
    "    netloc TEXT NOT NULL,\n",
    "    date TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL\n",
    "    );\n",
    "\"\"\") # 나중에 본문 내용 빼놓고 이미지,텍스트로 분기도 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseURL(seed):\n",
    "    html = download(\"get\",seed)\n",
    "    dom = BeautifulSoup(html.text,\"lxml\")\n",
    "    \n",
    "    return [compat.urljoin(seed,_[\"href\"]) # 특정 depth까지만\n",
    "                 for _ in dom.find_all(\"a\") \n",
    "            if _.has_attr(\"href\") and len(_[\"href\"]) > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google\n",
    "url = 'https://www.google.com/search?newwindow=1&ei=rhwsXfmJLsj58QXyyZugAQ&q=%EB%B0%95%EB%B3%B4%EC%98%81&oq=%EB%B0%95%EB%B3%B4%EC%98%81&gs_l=psy-ab.3..0l2j0i131j0l7.233632.234700..234750...1.0..1.137.847.1j7......0....1..gws-wiz.....0..0i71.NbxV7mwYbnE'\n",
    "param = getparams(url)\n",
    "urlsrc = geturl(url)\n",
    "\n",
    "html = download('get',urlsrc,param)\n",
    "dom = BeautifulSoup(html.text,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (1,)\n",
      "2 (2,)\n",
      "3 (2,)\n",
      "4 (3,)\n",
      "5 (4,)\n",
      "6 (5,)\n",
      "7 (6,)\n",
      "8 (7,)\n",
      "9 (8,)\n"
     ]
    }
   ],
   "source": [
    "for href in [_.find_parent()[\"href\"] for _ in dom.select(\".LC20lb\")]:\n",
    "    \n",
    "    _urlparse = compat.urlparse(href)\n",
    "    netloc = \"://\".join(_urlparse[:2])\n",
    "    cur.execute(\"SELECT id FROM table2 WHERE netloc = ? LIMIT 0,1\"\n",
    "                ,[netloc]) # netloc은 sequence로 만들어야함\n",
    "    \n",
    "    netlocID = cur.fetchone()\n",
    "    if not netlocID:\n",
    "        cur.execute(\"INSERT INTO table2 (netloc) VALUES(?)\"\n",
    "                    ,[netloc])\n",
    "        con.commit()\n",
    "        cur.execute(\"SELECT id FROM table2 WHERE netloc = ? LIMIT 0,1\"\n",
    "                ,[netloc])\n",
    "        netlocID = cur.fetchone()\n",
    "        \n",
    "    cur.execute(\"INSERT INTO table1(table2_id,path,param,depth,inbound)\\\n",
    "    VALUES(?,?,?,?,?)\",[netlocID[0],_urlparse[2],_urlparse[4],1,0])\n",
    "    con.commit()\n",
    "    print(cur.lastrowid,netlocID)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-428-4aba06ca05b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m         VALUES(?,?,?,?,?)\",[netlocID[0],_urlparse[2],_urlparse[4],seed[4]+1,\n\u001b[0;32m     43\u001b[0m                            seed[5]])\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mcon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while True:\n",
    "    cur.execute(\"\"\"\n",
    "    SELECT table1.id,table2.netloc,\n",
    "           table1.path,table1.param,\n",
    "           table1.depth, table2.id\n",
    "    FROM table1\n",
    "    JOIN table2 ON table1.table2_id=table2.id\n",
    "    WHERE table1.seen = FALSE and table1.depth < 3\n",
    "    ORDER BY table1.date ASC\n",
    "    LIMIT 0,1;\n",
    "    \"\"\")\n",
    "    seed = cur.fetchone()\n",
    "    if not seed:\n",
    "        break;\n",
    "    \n",
    "    cur.execute(\"\"\"\n",
    "        UPDATE table1\n",
    "        SET seen=TRUE\n",
    "        where id = ?\n",
    "    \"\"\",[seed[0]])\n",
    "    con.commit()\n",
    "    \n",
    "    baseURL = \"{0}{1}?{2}\".format(seed[1],seed[2],seed[3]) # 주소 만들기\n",
    "    for href in parseURL(baseURL):\n",
    "\n",
    "        _urlparse = compat.urlparse(href)\n",
    "        netloc = \"://\".join(_urlparse[:2])\n",
    "        cur.execute(\"SELECT id FROM table2 WHERE netloc = ? LIMIT 0,1\"\n",
    "                    ,[netloc]) # netloc은 sequence로 만들어야함\n",
    "\n",
    "        netlocID = cur.fetchone()\n",
    "        if not netlocID:\n",
    "            cur.execute(\"INSERT INTO table2 (netloc) VALUES(?)\"\n",
    "                        ,[netloc])\n",
    "            con.commit()\n",
    "            cur.execute(\"SELECT id FROM table2 WHERE netloc = ? LIMIT 0,1\"\n",
    "                    ,[netloc])\n",
    "            netlocID = cur.fetchone()\n",
    "\n",
    "        cur.execute(\"INSERT INTO table1(table2_id,path,param,depth,inbound)\\\n",
    "        VALUES(?,?,?,?,?)\",[netlocID[0],_urlparse[2],_urlparse[4],seed[4]+1,\n",
    "                           seed[5]])\n",
    "        con.commit()\n",
    "    i+=1\n",
    "    if i==1000:\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"INSERT INTO table1(table2_id,path,param)\\\n",
    "        VALUES(?,?,?)\",[10,'',''])\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ParseResult(scheme='https', netloc='namu.wiki', path='/w/%EB%B0%95%EB%B3%B4%EC%98%81', params='', query='', fragment=''),\n",
       " ParseResult(scheme='https', netloc='ko.wikipedia.org', path='/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', params='', query='', fragment=''),\n",
       " ParseResult(scheme='https', netloc='ko.wikipedia.org', path='/wiki/%EB%B0%95%EB%B3%B4%EC%98%81%EC%9D%98_%EC%9E%91%ED%92%88_%EB%AA%A9%EB%A1%9D', params='', query='', fragment=''),\n",
       " ParseResult(scheme='https', netloc='news.joins.com', path='/article/22895953', params='', query='', fragment=''),\n",
       " ParseResult(scheme='https', netloc='movie.daum.net', path='/person/main', params='', query='personId=105244', fragment=''),\n",
       " ParseResult(scheme='http', netloc='m.cafe.daum.net', path='/parkboyoungfd', params='', query='', fragment=''),\n",
       " ParseResult(scheme='https', netloc='www.msn.com', path='/ko-kr/entertainment/tv/hd%EC%8A%A4%ED%86%A0%EB%A6%AC-%EC%9E%91%EC%9D%80-%EA%B1%B0%EC%9D%B8-%EB%B0%95%EB%B3%B4%EC%98%81%E2%80%A6%EA%B7%B8%EC%9D%98-%EC%97%B0%EA%B8%B0%EC%97%90-%EB%8C%80%ED%95%9C-%ED%9D%94%EC%A0%81%EB%93%A4/ar-BBUvL0V', params='', query='', fragment=''),\n",
       " ParseResult(scheme='https', netloc='twitter.com', path='/hashtag/%EB%B0%95%EB%B3%B4%EC%98%81', params='', query='', fragment=''),\n",
       " ParseResult(scheme='http', netloc='www.epochtimes.co.kr', path='/news/articleView.html', params='', query='idxno=415565', fragment='')]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[compat.urlparse(_.find_parent()[\"href\"]) for _ in dom.select(\".LC20lb\")]\n",
    "# params는 post방식에서 넘기는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"SELECT id FROM table2 WHERE netloc = ? LIMIT 0,1\"\n",
    "                ,[netloc])\n",
    "cur.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queue: 45, Seen: 1\n",
      "Queue: 61, Seen: 2\n",
      "Queue: 85, Seen: 3\n",
      "Queue: 92, Seen: 4\n",
      "Queue: 91, Seen: 5\n",
      "Queue: 90, Seen: 6\n",
      "Queue: 89, Seen: 7\n",
      "Queue: 88, Seen: 8\n",
      "Queue: 87, Seen: 9\n",
      "Queue: 86, Seen: 10\n",
      "Queue: 85, Seen: 11\n",
      "Queue: 84, Seen: 12\n",
      "Queue: 83, Seen: 13\n",
      "Queue: 82, Seen: 14\n",
      "Queue: 81, Seen: 15\n",
      "Queue: 80, Seen: 16\n",
      "Queue: 79, Seen: 17\n",
      "Queue: 78, Seen: 18\n",
      "Queue: 77, Seen: 19\n",
      "Queue: 76, Seen: 20\n",
      "Queue: 75, Seen: 21\n",
      "Queue: 74, Seen: 22\n",
      "Queue: 73, Seen: 23\n",
      "Queue: 72, Seen: 24\n",
      "Queue: 71, Seen: 25\n",
      "Queue: 70, Seen: 26\n",
      "Queue: 69, Seen: 27\n",
      "Queue: 68, Seen: 28\n",
      "Queue: 67, Seen: 29\n",
      "Queue: 66, Seen: 30\n",
      "Queue: 65, Seen: 31\n",
      "Queue: 64, Seen: 32\n",
      "Queue: 63, Seen: 33\n",
      "Queue: 62, Seen: 34\n",
      "Queue: 61, Seen: 35\n",
      "Queue: 60, Seen: 36\n",
      "Queue: 59, Seen: 37\n",
      "Queue: 58, Seen: 38\n",
      "Queue: 57, Seen: 39\n",
      "Queue: 56, Seen: 40\n",
      "Queue: 55, Seen: 41\n",
      "Queue: 54, Seen: 42\n",
      "Queue: 53, Seen: 43\n",
      "Queue: 52, Seen: 44\n",
      "Queue: 51, Seen: 45\n",
      "Queue: 50, Seen: 46\n",
      "Queue: 49, Seen: 47\n",
      "Queue: 48, Seen: 48\n",
      "Queue: 47, Seen: 49\n",
      "Queue: 46, Seen: 50\n",
      "Queue: 45, Seen: 51\n",
      "Queue: 44, Seen: 52\n",
      "Queue: 43, Seen: 53\n",
      "Queue: 42, Seen: 54\n",
      "Queue: 41, Seen: 55\n",
      "Queue: 40, Seen: 56\n",
      "Queue: 39, Seen: 57\n",
      "Queue: 38, Seen: 58\n",
      "Queue: 37, Seen: 59\n",
      "Queue: 36, Seen: 60\n",
      "Queue: 35, Seen: 61\n",
      "Queue: 34, Seen: 62\n",
      "Queue: 33, Seen: 63\n",
      "Queue: 32, Seen: 64\n",
      "Queue: 31, Seen: 65\n",
      "Queue: 30, Seen: 66\n",
      "Queue: 29, Seen: 67\n",
      "Queue: 28, Seen: 68\n",
      "Queue: 27, Seen: 69\n",
      "Queue: 26, Seen: 70\n",
      "Queue: 25, Seen: 71\n",
      "Queue: 24, Seen: 72\n",
      "Queue: 23, Seen: 73\n",
      "Queue: 22, Seen: 74\n",
      "Queue: 21, Seen: 75\n",
      "Queue: 20, Seen: 76\n",
      "Queue: 19, Seen: 77\n",
      "Queue: 18, Seen: 78\n",
      "Queue: 17, Seen: 79\n",
      "Queue: 16, Seen: 80\n",
      "Queue: 15, Seen: 81\n",
      "Queue: 14, Seen: 82\n",
      "Queue: 13, Seen: 83\n",
      "Queue: 12, Seen: 84\n",
      "Queue: 11, Seen: 85\n",
      "Queue: 10, Seen: 86\n",
      "Queue: 9, Seen: 87\n",
      "Queue: 8, Seen: 88\n",
      "Queue: 7, Seen: 89\n",
      "Queue: 6, Seen: 90\n",
      "Queue: 5, Seen: 91\n",
      "Queue: 4, Seen: 92\n",
      "Queue: 3, Seen: 93\n",
      "Queue: 2, Seen: 94\n",
      "Queue: 1, Seen: 95\n",
      "Queue: 0, Seen: 96\n"
     ]
    }
   ],
   "source": [
    "queue = list()\n",
    "queue.extend([_.find_parent()[\"href\"] for _ in dom.select(\".LC20lb\")])\n",
    "seen = list()\n",
    "\n",
    "while queue:\n",
    "    baseURL = queue.pop(0) \n",
    "    seen.append(baseURL)\n",
    "    \n",
    "    time.sleep(0.1) # 너무 빠르면 안된다.\n",
    "    \n",
    "    linkList = parseURL(baseURL)\n",
    "    for link in linkList:  # 중복되는 url은 빼주어야 한다. (Home 같은 것)\n",
    "        if link not in queue and link not in seen:\n",
    "            queue.append(link)\n",
    "    print(\"Queue: {0}, Seen: {1}\".format(len(queue),len(seen)))\n",
    "\n",
    "    \n",
    "# Focused crawling은 얼마나 레퍼런스됬는지 볼때사용됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParseResult(scheme='https', netloc='namu.wiki', path='/w/%EB%B0%95%EB%B3%B4%EC%98%81', params='', query='', fragment='')"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compat.urlparse(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select inbound,count(inbound)\n",
    "from table1 where table2_id=2 group by inbound;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 979), (10, 1310)]"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"\"\"\n",
    "    select inbound,count(inbound)\n",
    "    from table1 \n",
    "    where table2_id=10 group by inbound;\n",
    "\"\"\")\n",
    "cur.fetchall() # outbound 보기 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(35768,)]"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"\"\"\n",
    "    select count(inbound)\n",
    "    from table1 \n",
    "    where inbound=1;\n",
    "\"\"\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 979/35768이 1번 사이트의 가중치이다.\n",
    "- 정보의 중요성이 얼마나 되는지 볼 때 inbound, outbound를 이용한 rank를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 내일은 contents를 담는 table만들어서 엮을 것임.\n",
    "- 원하는 data 뽑아서 넣을 것임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
